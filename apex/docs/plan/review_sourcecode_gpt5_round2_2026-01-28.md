OK, mÃ¬nh Ä‘á»c **toÃ n bá»™ code + sá»‘ Ä‘o** rá»“i.
KhÃ´ng vÃ²ng vo ná»¯a, Ä‘Ã¢y lÃ  **phÃ¡n quyáº¿t ká»¹ thuáº­t cuá»‘i cÃ¹ng cho Phase 1**.

---

# ğŸ§¨ PHÃN QUYáº¾T Dá»¨T KHOÃT

> **Phase 1 KHÃ”NG Ä‘Æ°á»£c phÃ©p dá»«ng á»Ÿ 32k RPS.**
> NhÆ°ng **Phase 1 cÅ©ng KHÃ”NG nÃªn lao vÃ o custom pool phá»©c táº¡p.**

ğŸ‘‰ **Cáº£ hai hÆ°á»›ng báº¡n Ä‘á» xuáº¥t Ä‘á»uâ€¦ sai thá»i Ä‘iá»ƒm.**

* âŒ *â€œDá»«ng Phase 1 á»Ÿ Ä‘Ã¢yâ€* â†’ **FAIL invariant** (vs Traefik, vs echo)
* âŒ *â€œImplement custom pool crossbeam / affinityâ€* â†’ **Phase 2.5 masquerading as Phase 1**

ğŸ‘‰ **CÃ“ má»™t con Ä‘Æ°á»ng thá»© 3**, Ä‘Ãºng vá»›i proposal gá»‘c, Ä‘Ãºng vá»›i Phase 1, vÃ  **cÃ³ kháº£ nÄƒng Ä‘Æ°a báº¡n lÃªn 60â€“70k RPS mÃ  KHÃ”NG viáº¿t custom pool**.

---

# ğŸ”¥ Sá»° THáº¬T KHÃ“ NUá»T: Báº¡n Ä‘ang benchmark SAI THá»¨

## Báº¡n nghÄ© bottleneck lÃ  `hyper-util::Client`

âŒ Sai **má»™t ná»­a**.

### Bottleneck tháº­t lÃ :

> **Báº¡n Ä‘ang dÃ¹ng hyper nhÆ° â€œclient libraryâ€,
> trong khi echo server Ä‘ang dÃ¹ng hyper nhÆ° â€œprotocol engineâ€.**

Hai thá»© nÃ y **KHÃ”NG cÃ¹ng táº§ng trá»«u tÆ°á»£ng**.

---

# ğŸ” SO SÃNH TRá»°C DIá»†N (Ráº¤T QUAN TRá»ŒNG)

## Echo server

```rust
http1::Builder::new()
    .serve_connection(io, service_fn(handle))
```

* 1 TCP connection
* 1 task
* Request loop cháº¡y **inline**
* KhÃ´ng client abstraction
* KhÃ´ng pooling logic
* KhÃ´ng timeout wrapper
* KhÃ´ng future composition

ğŸ‘‰ ÄÃ¢y lÃ  **fast path tuyá»‡t Ä‘á»‘i** cá»§a hyper.

---

## Apex proxy (hiá»‡n táº¡i)

```rust
self.client.forward_streaming(...)
```

BÃªn trong:

* hyper-util legacy Client
* Timeout wrapper
* Connection pool
* Trait-based Service
* Task hopping
* Error wrapping
* Client-side state machine

ğŸ‘‰ Báº¡n Ä‘ang **benchmark framework overhead**, khÃ´ng pháº£i protocol overhead.

---

# ğŸš¨ Káº¾T LUáº¬N Cá»T LÃ•I

> **Phase 1 khÃ´ng cáº§n â€œconnection poolâ€.
> Phase 1 cáº§n â€œconnection ownershipâ€.**

---

# ğŸ§  GIáº¢I PHÃP ÄÃšNG CHO PHASE 1 (KHÃ”NG CROSSBEAM, KHÃ”NG MUTEX)

## âœ… MÃ” HÃŒNH: **Connection-per-backend-task**

### Ã tÆ°á»Ÿng

* Má»—i backend:

  * **1 task riÃªng**
  * **1 persistent HTTP/1.1 connection**
* Proxy:

  * Gá»­i request qua `tokio::mpsc`
  * Nháº­n response qua `oneshot`

ğŸ‘‰ KhÃ´ng pool.
ğŸ‘‰ KhÃ´ng lock.
ğŸ‘‰ KhÃ´ng affinity hack.
ğŸ‘‰ KhÃ´ng work-stealing issue.

---

## ğŸ§± Kiáº¿n trÃºc

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Request â†’  â”‚ ProxyService  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ mpsc
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ BackendTask (1/backend)â”‚
        â”‚ - owns SendRequest     â”‚
        â”‚ - loop send_request    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
              TCP connection
```

---

## âœ¨ VÃ¬ sao cÃ¡ch nÃ y ÄÃšNG cho Phase 1

| TiÃªu chÃ­                | ÄÃ¡nh giÃ¡            |
| ----------------------- | ------------------- |
| KhÃ´ng Mutex             | âœ…                   |
| KhÃ´ng crossbeam         | âœ…                   |
| KhÃ´ng custom pool       | âœ…                   |
| KhÃ´ng hyper-util Client | âœ…                   |
| Gáº§n echo server model   | âœ…                   |
| PhÃ¹ há»£p proposal        | âœ…                   |
| Äáº¡t 60â€“70k RPS?         | **Ráº¤T CÃ“ KHáº¢ NÄ‚NG** |

---

# ğŸ“Œ Táº I SAO thread_local + pool FAIL (báº¡n Ä‘Ã£ tháº¥y)

Báº¡n Ä‘Ãºng khi káº¿t luáº­n:

> âŒ thread_local khÃ´ng work vá»›i tokio work-stealing

â†’ VÃ¬ request **khÃ´ng stick vá»›i OS thread**.
â†’ ÄÃ¢y lÃ  lÃ½ do proposal gá»‘c **chÆ°a bao giá» há»©a thread_local Phase 1**.

---

# ğŸ§ª VÃŒ SAO connection-per-request = 2.7k RPS

* TCP handshake
* HTTP handshake
* No keep-alive reuse

â†’ ÄÃ¢y lÃ  **expected**. KhÃ´ng pháº£i failure.

---

# ğŸ¯ Lá»˜ TRÃŒNH CHUáº¨N (KHÃ”NG ÄI Táº®T)

## Phase 1 (báº¯t buá»™c)

âŒ hyper-util::Client
âŒ connection pool
âŒ per-worker pool

âœ… **BackendTask + mpsc**
âœ… Persistent SendRequest
âœ… 1 backend = 1 task

ğŸ‘‰ **Target:** 60â€“70k RPS
ğŸ‘‰ **Overhead:** ~15â€“25% (cháº¥p nháº­n Ä‘Æ°á»£c)

---

## Phase 2

* Pool nhiá»u connections / backend
* Adaptive concurrency
* Health + circuit breaker gáº¯n vÃ o task
* Backpressure-aware routing

---

## Phase 3

* Per-worker pool
* Cache-line tuning
* io_uring
* HTTP/2, H3

---

# ğŸ§¨ PHÃN QUYáº¾T CUá»I

> **Phase 1 KHÃ”NG Ä‘Æ°á»£c dá»«ng.
> NhÆ°ng Phase 1 cÅ©ng KHÃ”NG Ä‘Æ°á»£c â€œÄ‘á»‘t nÃ£oâ€ vÃ o custom pool.**

ğŸ‘‰ **BackendTask model lÃ  con Ä‘Æ°á»ng duy nháº¥t vá»«a Ä‘Ãºng ká»¹ thuáº­t, vá»«a Ä‘Ãºng chiáº¿n lÆ°á»£c.**

---

## Báº¡n chá»n bÆ°á»›c tiáº¿p theo nÃ o?

**A.** MÃ¬nh viáº¿t **prototype BackendTask + mpsc** (drop-in thay HttpClient)
**B.** MÃ¬nh váº½ **sequence diagram + invariants** cho BackendTask
**C.** MÃ¬nh chá»‰ ra **exact code cáº§n xÃ³a / thay** trong repo hiá»‡n táº¡i
**D.** Dá»«ng Phase 1 (âš ï¸ mÃ¬nh sáº½ pháº£n Ä‘á»‘i)

Chá»n **1**.
